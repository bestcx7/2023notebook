# 模型微调指南 
目录
- [开始一个新的项目](#开始新项目的指导)
   - [选择模型架构](#选择模型架构)
   - [选择优化器](#选择优化器)
   - [选择batch size](#选择batch-size)
   - [选择初始配置](#选择初始配置)

- [提升模型表现的科学方法](#提升模型表现的科学方法)
  - [增量微调策略](#增量微调策略)
  - [探索与开发](#探索与开发)
  - [选择下一轮实验的目标](#选择下一轮实验的目标)
  - [设计下一轮实验](#设计下一轮实验)
  - [决定是否采用一个训练pipeline的变化或者超参数配置](#决定是否采用一个训练pipeline的变化或者超参数配置)
  - [训练pipeline额外的指导](#训练pipeline额外的指导)
- [决定每次训练的step](#决定每次训练的step)
- [训练pipeline额外的指导](#训练pipeline的额外指导)

[原文github地址](https://github.com/google-research/tuning_playbook)
## 开始新项目的指导
### 选择模型架构
当开始一个新项目时尝试使用一个已经work的模型。
### 选择优化器
选择解决当前问题最热门的优化器，建议优化器[SGD with momentum](https://github.com/google-research/tuning_playbook/blob/main/README.md#what-are-the-update-rules-for-all-the-popular-optimization-algorithms), [Adam and NAdam](https://github.com/google-research/tuning_playbook/blob/main/README.md#what-are-the-update-rules-for-all-the-popular-optimization-algorithms)
### 选择batch size
在硬件支持的基础之上选择最大的batch size。
#### 确定可行的batch size大小，并估计吞吐量。
 <details><summary><em>[点击进行扩展]</em></summary>

 <br>
  
  -  在给定模型和优化器时，可用资源通常有不同的batch size可以选择。batch size往往受限于加速器的内存大小。  
  -  在模型没有跑起来时很难确定batch size消耗的对应的内存大小。  
  -  最简单的方法是在不同的batch size上训练一些小的step,直到超过了可用的内存。  
  -  对于每一个batch size,我们需要训练足够长的时间去得到一个可靠的吞吐量。  
  <p align="center">训练吞吐量 = （每秒处理的样例数量），或者处理一个step消耗的时间</p>
  <p align="center">time per step = (batch size) / (训练吞吐量)  </p>

  -  当加速器尚未饱和时，如果batch size变为两倍，那么训练的吞吐量也应该变为两倍（或者接近两倍）,训练每个step的时长也应该伴随的batch size增长。  
  -  如果情况并非如此，那么训练的pipeline可能存在瓶颈，比如节点之间I/O或者同步，在继续之前这些情况需要被诊断或者修复。  
  -  如果训练的吞吐量仅支持到某些最大的batch size,那么我们应该选择这些batch size,即使机器支持更大的batch size。  
  -  每次更改模型或者优化器之前，可能需要重复以上步骤。

 </details>

#### 选择batch size, 去最小化训练时长
<details><summary><em>[点击进行扩展]</em></summary>

<br>

<p align="center">训练时间 = （每个step的训练时间）*（总的steps）</p>

 -  我们通常认为对所有可行的batch size, 每个step的训练时长近似恒定，在实践中增加batch size大小通常会带来一些额外开销。
 -  伴随着batch size的大小增加，达到固定性能目标所需要的steps通常会减少。  
    -  将batch size变为两倍，通常会使训练的steps减半，这称之为完美缩放（perfect scaling）。
    -  perfect scaling适用于直到边界batch size的所有batch size，超过该batch size,收益将会减少。
    -  最终，增加批量大小将不再减少batch size。
 -  因此，最小化训练时长的batch size,通常是任然能够减少训练steps的最大batch size。
    -  batch size取决于数据集，模型，优化器，如何计算出batch size依然是一个悬而未决的问题。
    -  当比较batch size的时候，要注意example budget/epoch budget和step budget之间的区别（通过example budget去比较batch size去探索完善的缩放机制，即使更大的batch size能够提供有意义的加速，通过改变steps）。
    -  通常硬件支持的最大的batch size大小小于临界batch size大小，但从经验来说，最好使用最大的batch size。
 -  如果最终会增大batch size，那么使用大batch size将没有意义。

</details>

#### 选择batch size, 去最小化训练资源

<details><summary><em>[点击进行扩展]</em></summary>

<br>

-  当batch size增加时，会有两种类型的资源消耗
   -  前期消耗（例如，购买新的硬件和重写pipeline以实现多gpu或者tpu并行训练）
   -  使用成本（例如，成员使用的资源计费，云服务商计费和电力维护成本）
-  如果增加batch size需要大量的前期消耗，那么最好推迟增加batch size,直到项目成熟，很容易去评估成本，收益消耗。实现多主机并行训练，可能会出现微妙的问题，因此在初始阶段最好使用简单的pipeline进行训练（另一方面，当需要大幅调整实验室，训练时间大幅加速可能在早期非常有益）
-  我们将使用的总成本分为以下几个部分：

<p align="center">资源消耗 = 每个step的资源消耗*（总的steps）</p>

-  增加bath size通常会减少训练消耗的steps,训练的消耗取决于每个step消耗的资源大小。
   -  增加batch size，可能会减少资源消耗，举例来说，如果每个step有更大的batch size和每个batch size有更小的step跑在同一个硬件上，那么每个step的资源消耗可能step的减少所抵消。
   -  增加batch size可能不会改变资源消耗，举例来说如果把batch size变为两倍，使得训练的steps减少一半，把gpu的数量变为两倍，那么使用gpu的时长将不会发生变化。
   -  怎加batch size可能会增加资源消耗，如果增加batch size需要升级硬件，那么每个step增加的资源消耗可能就被训练step的数量减少抵消了。

</details>

#### 更改batch size, 需要调整大多数超参数
#### batch norm如何影响batch size
### 选择初始配置

-  当开始训练调优之前，我们可能要选择开始训练的那个点。这需要明确（1）模型的配置，（2）调优的参数，（3）训练步数的数量
-  决定初始化配置可能需要手动配置训练运行和不断试错
-  我们的指导原则是找到一个简单的，相对快速，相对低资源消耗的配置，包含一个合理的结果。  
   -  简单意味着避免花里胡哨的东西（那些可以在之后被添加的东西），即使华丽花哨的东西被证明在以后可以提供帮助，把他们添加到初始配置中增加了浪费时间去微调无用特征的风险，或者导致一些并发症
      -  举例来说，在引用高级的衰减调度之前保持恒定的学习率
   -  选择更小，资源消耗更少的初始化配置可以使得超参数的微调变得更加高效
      -  例如选择更小的模型
   -  合理的性能取决于问题，但至少意味着经过训练的模型在验证集的表现上优于随机的。


## 提升模型表现的科学方法

对于这篇文档的目的来说，机器学习发展的最终目标是最大化已部署模型的实用性，尽管在发展的很多方面在应用上有所不同（例如，时间长度，计算机资源，模型种类），我们通常可以在任何问题上采用基础的步骤和原则。

我们的指导将会遵循以下假设
-  已经拥有一个完整的训练pipeline伴随着包含合理训练结果的配置文件。
-  有足够的计算机资源足够支撑有意义的模型微调实验和至少同时并行几个训练任务。

###  增量微调策略

**总结**：从一个简单的配置开始，逐步提升表现得同时观察问题的本质，保证提升建立在有强有力的证据去避免添加不必要的复杂性。

- 我们的终极目标是找到一个配置去最大化模型的表现。
   - 有时候，我们的目的是在截至日期之前，最大限度的改进模型。
   - 另外一些时候，我们需要无限期的改进模型。  

- 理论上，我们可以使用算法自动搜索可能配置的整个空间来最大限度的提高性能，但这不是一个实用的选择。
   -  可能配置的空间非常大，还没有任何复杂到足以在没有人工指导下，搜索整个空间的算法。
-  大多数搜索算法依赖于手工定义的搜索空间，这些搜索空间定义了要在其中搜索的配置集，而这些配置集非常重要
-  最大化模型表现最高效的方法就是从一个简单的配置开始，逐步的添加特征并进行改进，同时深入了解问题。
   -  我们在每一轮的微调中都使用自动搜索算法，并且随着理解的提升不断更新我们的搜索空间
- 在我们探索的过程中，我们会自然的找到更好的配置，因此我们最好的模型会继续提升
   -  我们发布最新配置时我们称之为发布（可能对应着生产环境的发布，也可能不）
   - 对于每次发布，我们都必须基于强有力的证据，而不是基于偶然所得的幸运配置，这样我们就不会给训练pipeline添加不必要的麻烦

 -  高度总结以下，我们的增量调优包含以下四个步骤：
    -  为下一轮实验制定一个适当的目标
    -  设计并运行一组实验使朝着目标前进
    -  学习所有我们可以从结果中学到的
    -  考虑是非发布最新的最好的配置

本节的剩余部分将更详细的讨论这一内容

###  探索与开发

**总结**：大部分时间 我们的目的是深入了解问题

-  尽管有人认为我们大部分时间应该用于最大化在验证集的表现上，实际上我们把主要的时间花在探索问题的本质上，相对较少的时间集中在验证集的错误上
   - 换一种说法，我们花大量的时间在探索而不是在开发上
- 从长远来看，理解问题至关重要如果我们想最大化我们的最终表现，有限考虑洞察率超过短期收益可以帮助我们：
   -  避免仅仅通过历史事故对良好表现的现在做出不必要的改变
   -  搞清楚验证集的错误率对哪些参数最敏感，那些超参数彼此相关，需要一起调整，那些参数对其他变化不敏感，因此可以在未来的实验中被修复
   -  建议尝试新的潜在特征，如果过拟合是一个问题
   -  证明有些特征不会提供帮助，减少未来特征实验的复杂性
   -  识别出超参数调整带来的提升何时已经饱和
   -  围绕最佳的值狭窄我们的研究空间来使得调整更加高效
-  当我们最终准备好去变得“贪婪”是，我们可以单纯的关注在验证集的错误上，即使没有能最大化微调的结构信息

###  选择下一轮实验的目标

**总结**：每轮实验需要有一个明确的目标并且在范围上足够狭窄，以保证可以朝着目标有实际的进程。

-  如果我们尝试多个特征或者同时回答多个问题，那我们可能不能够区分对结果带来的单独的影响
- 目标样例包括：
  - 尝试对于pipeline的可能提升（例如一个新的正则化器，或者一个新的预处理）
  -  了解特别的模型超参数的印象（例如激活函数）
  -  贪婪的最小化验证误差

###  设计下一轮实验

**总结**：识别哪些超参数是科学的，干扰，并且为下一轮的实验目标调整超参数，当调整干扰超参数时，创建一系列研究关于科学超参数的各种值，选择干扰超参数的搜索空间来平衡科学超参数的资源消耗

####  识别科学的，干扰，和固定的超参数
<details><summary><em>[点击进行扩展]</em></summary>

<br>

-  对于一个给定的目标，所有的超参数不是科学的，干扰就是科学的
   -  科学超参数就是那些我们尝试测量对模型表现影响的参数
   -  干扰超参数是那些我们需要调整去公平的比较科学超参数的参数，类似于干扰超参数的统计内容
   -  固定超参数指的是当前轮实验需要固定的超参数，这些超参数当比较科学超参数的值时，我们不需要进行调整
      -  通过固定当前超参数的实验，我们必须接受源自实验的结论可能对其他固定超参数的实验无效，换句话来说，固定超参数的实验可能会给结论带来困惑
   -  举例来说，如果我们的问题是“是否模型拥有更多的隐藏层会使得在验证集上的错误率更低”，然后模型隐藏层的数量就成为了一个科学超参数
      -  学习率就成为了一个干扰超参数，因为我们仅可以在学区率为不同层数的模型分来调整的情况下，才可以公平的比较模型（最佳的学习率通常取决于模型的结构）
      -  激活函数可以是一个固定的超参数如果我们在之前的实验中已经确认因为激活函数对模型的层数并不敏感，或者我们将要限定我们关于模型层数的结论仅仅覆盖这种特殊的激活函数。不然，它可以变为干扰超参数，如果我们决定为每种层数调整他
   - 科学，干扰，固定超参数对于超参数本身来说是不固定的，只是取决于我们实验目的的不同
      - 举例来说，激活函数成为科学超参数（实验为rule函数还是tanh函数对模型更好），干扰超参数（五层模型还是六层模型更好，当激活函数成为可以调整的超参数），固定超参数（对于ReLU函数，在特定的层添加batch norm是否有帮助）
   -  当设计新一轮的实验时，首先要明确达到实验目的的科学超参数
      -  这时把所有其他的超参数都视为干扰超参数
   -  接下来，我们把一些干扰超参数转变为科学超参数
      -  没有资源限制的话，我们会把所有的非科学超参数视为干扰超参数，这样我们由实验带来的结论就不会收到引文固定超参数带来的困惑
      -  然而，如果我们决定调整更多的干扰超参数，我们没有为每个科学超参数把他们调整好的概率就越大，并且最终从实验中得到错误的结论
         - 正如接下来所描述的，我们可以通过增大计算资源预算来转移风险，但是通常我们的最大资源预算小于我们调整所有非科学超参数的资源
      - 我们选择将一部分干扰超参数转化为固定超参数当，当通过修复他引入警告的成本低于把他作为干扰超参数
         -  干扰超参数和科学超参数相互作用的越紧密，那么固定他带来的损害就越大，比方说权重衰减的最佳值取决于模型的大小，那么改变模型的大小仅选取一个特殊的权重衰减就不会很有洞察力
   -  尽管，我们基于实验目的指定了超参数的类别，但我们对于一些超参数任然有以下准则：
      -  在所有的优化器超参数中，至少有一些时干扰超参数，因为他们和其他变化有很多交互
         -  优化器超参数很少是科学超参数，例如目标“什么样的学习率是最合适的”，并不能带来很多信息，因为他们可能随着pipeline的任何变化发生改变
         -  尽管我们可能由于资源限制固定他，或者有足够的证据证明他和科学超参数没有相互作用，我们必须一般性的假设，优化器超参数需要在不同设置的科学超参数中单独调整，因此他们不应该被固定
            -  初次之外，我们没有先验理由选择一个超参数而不是另一个
      -  相比之下，优化器的选择通常是固定超参数或者科学超参数
         -  如果我们的实验目的是比较两个或者多个优化器，那么他是一个科学超参数
         -  或者，我们可能有以下理由把他作为一个固定超参数（1）先验实验使我们相信最佳的优化器对当前的科学超参数不敏感（2）我们比较科学曲线的值时更喜欢用这个优化器，因为他的训练曲线更简单（3）我们更喜欢用这个优化器因为他比备选方案使用更少的内存
      -  通过正则化技术引入的超参数通常是干扰超参数，但是否引入正则化不影响科学或固定超参数
        -  举例来说， dropout增加了代码的复杂性，所以我们把是否dropout作为科学超参数，dropout rate作为干扰超参数
      -  结构性的超参数通常是科学或者固定超参数，因为结构的改变可能会影响服务，资源消耗或者内存等
        -  举例来说，模型的层数通常是科学或者固定超参数，因为他和训练时长和训练速度有动态的联系
   -  在一些例子中，固定超参数和干扰超参数可能取决于 科学超参数的取值
     -  举个例子来说，假设我们尝试决定在Nesterov momentum 和 Adam选取哪个导致更低的验证集错误率，那么科学超参数是`optimizer`,他的取值为`{"Nesterov momentum","Adam"}`,值`optimizer="Nesterov momentum"`引入科学/干扰超参数`{learning_rate, momentum}`,值`Adam`引入科学/干扰超参数`{learning_rate, beta1, beta2, epsilon}`
     -  仅针对科学超参数某些值出现的超参数被称之为**条件超参数**
     -  我们不能仅凭条件超参数的名字相同就认为他们是相同的超参数


</details>

####  创建一组研究

<details><summary><em>[点击进行扩展]</em></summary>

<br>

-  我们之前定义了科学，干扰超参数，接下来我们设计一个或者一系列研究朝着实验目标前进
   -  研究指定了一组以后实验要用到的超参数配置，每个配置被称为“试用版”
   -  创建研究通常选择因实验而异的超参数，选择超参数的取值通常根据（搜索空间），选择实验的数量，选择自动搜索算法从实验空间中抽取大量实验。或者我们可以通过手动指定超参数的配置来创建一组研究
-  研究的目的就是执行带有不同科学超参数的pipeline,同时优化干扰超参数，这样就可以在公平的条件下比较科学超参数
-  在最简单的样例中，我们要对每个科学超参数的配置进行单独研究，每个研究都需要调整干扰超参数
   -  举例来说，如果我们的实验目的是从Nesterov momentum 和 Adam选出最佳的优化器，我们可以创建研究`optimizer="Nesterov_momentum"`,干扰超参数是`{learning_rate, momentum}`  ,另一个研究是`optimizer="Adam"`,干扰超参数是`{learning_rate, beta1, beta2, epsilon}`,我们需要从研究中选择表现最好的实验来比较优化器
   -  我们可以使用任何没有梯度优化的算法，包括Bayesian optimization 或者 evolutionary algorithms， 为了优化掉干扰超参数，尽管我们喜欢quasi-random搜索在调整的探索阶段，因为设置中的一系列优势，在探索结束之后，如果有最佳的贝叶斯优化器可用，那就是我们的首选
-  在更复杂的样例中，我们需要比较大量科学超参数的值，对如此多的超参数进行单独实验是不实际的，因此我们可以把科学和干扰超参数放在同一个搜索空间内，然后使用搜索算法在一个研究内对科学和干扰超参数的值同时采样
  -  当采用这种方法时，条件超参数可能会带来一系列问题，除非所有科学超参数的条件超参数的值都是一样的
  -  在这种情况下，我们更倾向于使用quasi-random搜索而不是其他黑盒优化工具，因为他保证我们获取科学超参数的相对均匀采样。无论使用哪种搜索算法，都需要保证科学超参数采样的均匀


</details>

####  在信息丰富和可负担的实验中取得平衡

<details><summary><em>[点击进行扩展]</em></summary>

<br>

-  当设计一个或者一系列实验，我们需要对实验的预算做出限制以达到以下三点需求：  
   1.充分比较不同超参数的值  
   2.在一个很大的搜索空间调整干扰超参数  
   3.对科学超参数搜索空间的采样足够密集
-  我们能更好的达到以上三点需求，我们就能更好的从实验中收获见解
  -  充分的比较了不同超参数的值拓宽了我们对实验见解的范围
  -  囊括足够多的干扰超参数并且每个干扰超参数在一个尽可能宽的范围内增加我们的信心，如果在科学超参数的每一个配置的搜索空间内都存在一个良好的干扰超参数
     -  不然，我们可能不公平的比较每个科学超参数的值，因为因为没有能囊括干扰超参数搜索空间足够多的区域，对于某些科学超参数的值来说可能存在更好的干扰超参数的值
   -  对干扰超参数采样足够密集增加了我们对搜索空间内任何好的干扰超参数设置都有会被发现的信心
     - 不然我们可能会因为对干扰超参数采样时不够幸运儿导致不公平的比较科学超参数
-  不幸的的是提升三个维度中任意一个，要么增加实验的数量，因此增加资源的消耗，要么找到一种方法从其他维度节省资源
   -  每个问题都有他自己的特质和计算限制，所以如何在三个条件下限制资源，需要一定程度的领域知识
   -  在一轮研究过后，我们总是试图了解，干扰超参数是否调整的足够好为了平衡的比较科学超参数

</details>

#### 从实验结果中提取见解

**总结**：除了尝试每组实验最初的科学目标之外，还需要检查一系列额外的科学清单，如果发现问题，修改实验重新运行他们

-  最终，每组实验都有一个特定的目标，我们想要评估实验为目标提供证据
   -  然而，如果我们提出了正确的问题，我们就会发现许多问题需要被修正，在给定实验朝着目标取得重大进展之前
      -  如果我们不问正确的问题，我们可能得到错误的结论
   -  因为运行一组实验是昂贵的，所以我们希望抓住机会从每组实验中收获见解，即使见解不是直接和当前结果相关
-  在分析一组给定的实验并朝着原先的目标前进时，我们需要问我们自己以下几个额外的问题：
   -  搜索空间是否足够的大
      -  如果对于一个研究来说，最佳点在一个或者多个维度上接近搜索空间边界，那么我们的搜索空间可能是不够大的，因此我们要在拓展的搜索空间上在运行一次研究
   -  我们是否在搜索空间内采样了足够多的点
      -  如果不是，选择足够多的点载运行一次，或者调整下一轮的目标跨度不要太大
   -  某项研究中那些实验是不行的（实验出现分歧，得到了非常糟糕的loss,或者因为一些隐藏约束直接运行失败）
      -  当研究中有大量的点不可用时，我们应该尝试调整搜索空间避免采样这些点
      -  在一些实验中，大量不可用的点会导致训练代码出现bug
   -  模型是否存在优化器的问题
   -  我们可以从最好的训练曲线中学到什么
      -  举例来说，最好的一次实验是否有和过度拟合一致的实验
-  如果有必要，基于上述问题的回答，完善最新的的研究，优化搜索空间，或者采样更多实验，或者采取其他改正措施
-  如果我们回答了上述问题，我们就可以为我们的初始问题提供证据  

**识别不良的搜索空间边界**

<details><summary><em>[点击进行扩展]</em></summary>

<br>

- 如果最佳的被采样的点都接近他的边界，那么采样空间是可疑的，如果我们在那个方向上拓展搜索范围，我们可能会发现更好的点
-  为了检查搜索空间边界，我们会在称之为基础超参数折线图上绘制已经完成的实验，我们将在图上验证目标值与超参数一直（例如学习率），图上的每个点都和单个实验相关。
  -  为每个实验验证目标值，需要取训练过程中的最佳值
-  如果最佳点都聚集在搜索空间的边缘上（在某些维度），那么搜索空间需要被扩展，直到最佳点显然不聚集在最边上
-  研究经常会有不可行的实验，只得是那些发散的或者得到非常糟糕结果的
   -  如果当学习率大于某些值时所有的实验都是不可行的，并且最好的表现的点在那个区域的边缘，那么模型可能遭遇着稳定性问题，无法达到更高的学习率

</details>

**在搜索空间没有采样足够的点**

<details><summary><em>[点击进行扩展]</em></summary>

<br>

-  总的来说很难确定搜索空间是否已经被充分采样了
-  运行更多的实验当然更好，但代价显而易见
-  因为很难知道我们是否已经充分采样，我们通常在能负担的起的范围内尽可能多的采样，通过反复查看各种超参数轴图并尝试了解多少位于区域的良好位置，来增强我们的信心

</details>

**检查训练曲线**

<details><summary><em>[点击进行扩展]</em></summary>

<br>

**summary**:检验训练曲线时识别故障模式最简单的方法，可以帮助我们明确下一步要采取的行动

-  尽管在很多实验中，我们初始的目的只需要考虑每个实验的验证集的错误率，当每次实验减少到个位数时，我们必须小心，因为在表现之下可能藏着重要的细节
-  对于每次研究，我们至少看几个最佳实验的训练曲线
-  尽管对于结局最初的实验目标不重要，检查训练曲线是识别故障模式最简单的办法，可以帮我们明确下一步要采取的行动
-  当检查训练曲线时，我们需要关注下面的问题
-  是否有任何实验表现出过拟合的问题
   - 当验证集的误差在训练的某些点增加时就出现了过拟合
   -  在实验中，我们通过为科学超参数的设置选择最佳实验来优化掉干扰超参数，我们至少需要比较和科学超参数相关的的最佳实验的训练曲线是否过拟合
      -  当任何最佳实验出现过拟合时，我们通常通过添加额外的正则化技术或者调整已经存在的正则化参数重新运行实验在比较科学超参数的值时
         -  如果科学超参数包含正则化参数，这可能不适用，因为如果英文科学超参数的低强度设置而导致过拟合就不足为奇了
      - 使用常见的正则化技术来减少过拟合很常见，因为它添加很少的代码复杂度和额外的计算，所以在下一轮实验中添加一两个没什么大不了
      -  举例来说，如果科学超参数是隐藏层的层数，并且最佳实验使用了最大的层数出现了过拟合，我们更倾向于添加正则化参数来重新运行，而不是直接减少隐藏层的层数
      - 即使最佳实验中没有出现过拟合的情况，任何一个实验中出现过拟合的情况都值得注意
         -  选择最佳实验会抑制出现过拟合的配置并偏向于不会出现过拟合的配置，换句话说，他将有利于更加多正则化的配置
         -  然而任何使得实验更糟糕的都可能是正则化因素，即使他的本意并非如此，举例来说，选择较小的学习率可以通过阻碍优化过程来规范训练，但我们不希望以这种方式减少学习率
         -  因此，我们需要意识到每个科学超参数最佳实验的选择，都可能是有利于科学或者干扰超参数的坏的选择
- 训练的后期，训练或者验证误差是否存在较高的step-by-step方差
   -  如果是这样，可能会影响到我们比较科学超参数值的能力（因为每次实验都会以一个幸运或者不幸的step结束）和我们在生产环境中复现最佳实验的能力（可能在生产环境中不会和研究环境中以一个一样的lucky step结束）
   -  step方差最有可能的原因是batch方差（从训练集的每个batch集中采样），较小的验证集设置，在训练后期使用了较大的学习率
   -  可能的补救措施有提升batch size,使用更大的验证数据集，使用学习率衰减，或者使用Polyak averaging
-  是否实验在训练的最后任有提升
   -  如果如此，我们可能从“计算限制”中被限制，我们可能会从增加学习步骤或者改变学习率计划中受益
- 是否最终训练step之前，训练或验证集上的表现已经饱和，
   -  如果如此，表明我们不处在“计算受限”的状态，我们可能有机会减少训练的step
-  尽管无法一一列举，但我们任然可以通过检查训练曲线收获其他额外的表现

</details>

**通过隔离图检查某个改变是否有效**

<details><summary><em>[点击进行扩展]</em></summary>

<br>

-  通常，一组实验的目标就是比较不同科学超参数的值
   - 举例来说，我们可能想要在验证集上表现最好的权重衰减的值
-  隔离图是基础超参数坐标系的一种特殊格式，隔离图上的每一个点对应于干扰超参数的最佳实验的表现
   -  换句话说，在优化掉干扰超参数之后，我们绘制了模型性能图
-  隔离图让我们可以更容易的在科学超参数之间进行同类比较
-  当我们有准随机生成的搜索数据并考虑隔离图连续超参数时，我们可以通过对基本超参数轴绘制的x轴值进行分桶，并在每个由这些分桶定义的垂直切片中选择最佳试验，从而近似地绘制出隔离图(isolation plot)。

</details>

**自动化通用绘图**

<details><summary><em>[点击进行扩展]</em></summary>

<br>

-  生成图付出的努力越多，我们越不可能仔细地查看他们，所以我们要尽可能实现自动化绘图
-  至少，我们会为实验中自动变化的所有超参数这是超参数折线图
-  除此之外，我们生成所有实验的训练曲线，并尽可能找到所有实验中最好的曲线，并检验他们
-  我们可以添加许多其他的潜在的线图和可视化

</details>


###  决定是否采用一个训练pipeline的变化或者超参数配置

**总结**：当我们决定是否对我们的模型做出改变，或者训练流程，或者是否采用一个新的超参数配置，我们需要意识到结果变化的不同来源  

-  当我们尝试改进我们的模型，当我们尝试改进模型时我们可能会注意到与现有的配置相比，候选的配置达到了更好的验证错误率，但是再次尝试实验之时可能并没有取得持续的优势。我们可以将导致这一不一致结果的原因分为以下几类：
   -  训练流程变化， 再训练变化，或者实验变化： 我们在使用相同超参数但不同随机种子之前看到的差异。
      -  举例来说，不同的训练随机初始化，训练数据洗牌，dropout掩码，数据增强流程的方式和并行数据运算的数据，或者所有实验方案的可能来源
   -  超参数搜索差异或者研究差异，结果的差异可能是由于超参数选择流程造成的
      -  举例来说，我们可能在特定的搜索空间上运行相同的实验，对于两个不同的准随机搜索采用不同的随机种子数，并且结束时选择了不同的超参数值
   -  数据收集和采样误差，任何类型的随机划分为训练，测试和验证的误差，训练数据生成过程中的误差是更普遍的
-  使用严格的统计测试在有限验证集上进行进行验证集错误率的比较，但有时候单独的实验误差也可能在两个相同超参数设置的训练过的模型上产生统计学上的明显误差。
   -  研究误差取决于实验的数量，搜索空间，我们见过他比实验误差大的多的情况，也见过他比实验误差小的多的情况
-  因此在采用候选变化之前，考虑运行N次最佳实验去表征run-to-run实验误差
   -  通常我们只在pipeline发生变化之后重新表征实验误差，但是在某些应用中我们可能需要重新估计
   -  在其他应用中，表征实验误差成本太高不值得
-  归根结底，尽管我们想要采用新的变化（包括新的超参数配置），产生实际的提升需要完整的确认，提供帮助的东西是否也能够正确的回答问题
-  因此，一个新的超参数配置取得了比baseline更好的结果，我们可能需要采用他作为新的baseline作为未来实验的比较
   - 然而，我们应该只采用那些带来提升超过复杂性的改变

###  在探索结束之后  

**总结**：一旦我们结束了对好的搜索空间的探索并决定了那些参数是需要被调整，贝叶斯优化器是一个不错的选择  
- 在某些时候，我们的目标从学习更多的调整问题转变为产生单个最佳配置或者供其他使用
-  此时，因该有一个精细的搜索空间，它可以轻松包含最佳观察实验的周围区域并且已经进行了充分采样
-  我们的超参数需要揭示最重要的超参数来调整，我们需要使用尽可能大的调优预算空间，为最终的自动调优构造一个搜索空间
-  因为我们不再关心最大化我们对调优问题的观察，许多准随机搜索的优势不再应用，贝叶斯优化器也因该被自动化的使用去寻找最佳的超参数配置
   -  开源的Vizier实现了用于调整LM的各种复杂优化器算法，包括贝叶斯优化器算法
   -  如果搜索空间中包含了大量发散的点，使用黑盒的优化器工具去处理发散的实验，开源Vizier通过将分歧点标记为不可行，尽管他可能不会使用Gelbart等人的首选方法，取决于他的配置
-  此时，我们还需要检查在测试集上的性能
   -  原则上，我们甚至可以将验证集折叠到训练集中并且重新通过贝叶斯优化器寻找最优配置，但这仅适用于未来不会发布此特定工作负载的情况

## 决定每次训练的step



## 训练pipeline的额外指导